{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417295db",
   "metadata": {},
   "source": [
    "## 1. Import needed librairies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fc390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf611fb",
   "metadata": {},
   "source": [
    "## 2. Input the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91848678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsToxic</th>\n",
       "      <th>IsAbusive</th>\n",
       "      <th>IsThreat</th>\n",
       "      <th>IsProvocative</th>\n",
       "      <th>IsObscene</th>\n",
       "      <th>IsHatespeech</th>\n",
       "      <th>IsRacist</th>\n",
       "      <th>IsNationalist</th>\n",
       "      <th>IsSexist</th>\n",
       "      <th>IsHomophobic</th>\n",
       "      <th>IsReligiousHate</th>\n",
       "      <th>IsRadicalism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugg2KwwX0V8-aXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>If only people would just take a step back and...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugg2s5AzSPioEXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>Law enforcement is not trained to shoot to app...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugg3dWTOxryFfHgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>\\nDont you reckon them 'black lives matter' ba...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugg7Gd006w1MPngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>There are a very large number of people who do...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugg8FfTbbNF8IngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>The Arab dude is absolutely right, he should h...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CommentId      VideoId  \\\n",
       "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
       "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
       "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
       "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
       "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
       "\n",
       "                                                Text  IsToxic  IsAbusive  \\\n",
       "0  If only people would just take a step back and...    False      False   \n",
       "1  Law enforcement is not trained to shoot to app...     True       True   \n",
       "2  \\nDont you reckon them 'black lives matter' ba...     True       True   \n",
       "3  There are a very large number of people who do...    False      False   \n",
       "4  The Arab dude is absolutely right, he should h...    False      False   \n",
       "\n",
       "   IsThreat  IsProvocative  IsObscene  IsHatespeech  IsRacist  IsNationalist  \\\n",
       "0     False          False      False         False     False          False   \n",
       "1     False          False      False         False     False          False   \n",
       "2     False          False       True         False     False          False   \n",
       "3     False          False      False         False     False          False   \n",
       "4     False          False      False         False     False          False   \n",
       "\n",
       "   IsSexist  IsHomophobic  IsReligiousHate  IsRadicalism  \n",
       "0     False         False            False         False  \n",
       "1     False         False            False         False  \n",
       "2     False         False            False         False  \n",
       "3     False         False            False         False  \n",
       "4     False         False            False         False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('youtoxic_english_1000.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5af013",
   "metadata": {},
   "source": [
    "### Check if labels are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8160a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='IsToxic', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data=data,x=\"IsToxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c994656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsToxic</th>\n",
       "      <th>IsAbusive</th>\n",
       "      <th>IsThreat</th>\n",
       "      <th>IsProvocative</th>\n",
       "      <th>IsObscene</th>\n",
       "      <th>IsHatespeech</th>\n",
       "      <th>IsRacist</th>\n",
       "      <th>IsNationalist</th>\n",
       "      <th>IsSexist</th>\n",
       "      <th>IsHomophobic</th>\n",
       "      <th>IsReligiousHate</th>\n",
       "      <th>IsRadicalism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1000</td>\n",
       "      <td>13</td>\n",
       "      <td>997</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>UggiR-zPsqXFt3gCoAEC</td>\n",
       "      <td>9pr1oE34bIM</td>\n",
       "      <td>run them over</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>274</td>\n",
       "      <td>3</td>\n",
       "      <td>538</td>\n",
       "      <td>647</td>\n",
       "      <td>979</td>\n",
       "      <td>839</td>\n",
       "      <td>900</td>\n",
       "      <td>862</td>\n",
       "      <td>875</td>\n",
       "      <td>992</td>\n",
       "      <td>999</td>\n",
       "      <td>1000</td>\n",
       "      <td>988</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CommentId      VideoId           Text IsToxic IsAbusive  \\\n",
       "count                   1000         1000           1000    1000      1000   \n",
       "unique                  1000           13            997       2         2   \n",
       "top     UggiR-zPsqXFt3gCoAEC  9pr1oE34bIM  run them over   False     False   \n",
       "freq                       1          274              3     538       647   \n",
       "\n",
       "       IsThreat IsProvocative IsObscene IsHatespeech IsRacist IsNationalist  \\\n",
       "count      1000          1000      1000         1000     1000          1000   \n",
       "unique        2             2         2            2        2             2   \n",
       "top       False         False     False        False    False         False   \n",
       "freq        979           839       900          862      875           992   \n",
       "\n",
       "       IsSexist IsHomophobic IsReligiousHate IsRadicalism  \n",
       "count      1000         1000            1000         1000  \n",
       "unique        2            1               2            1  \n",
       "top       False        False           False        False  \n",
       "freq        999         1000             988         1000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ee9f9",
   "metadata": {},
   "source": [
    "The data is kinda balanced.\n",
    "Now we have to clean the text then vectorize it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18974a39",
   "metadata": {},
   "source": [
    "## 3. Clean the Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80c6980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\MSI\n",
      "[nltk_data]     I7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "154e00d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\MSI\n",
      "[nltk_data]     I7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\MSI\n",
      "[nltk_data]     I7\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "lemmatize=nltk.WordNetLemmatizer()\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7432a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d97f8",
   "metadata": {},
   "source": [
    "Remove xa0 space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74770803",
   "metadata": {},
   "outputs": [],
   "source": [
    "newData['Text'] = newData['Text'].replace(u'\\xa0', u' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca5146",
   "metadata": {},
   "source": [
    "Remove white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11c4953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newData['Text'] = newData['Text'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a482ec4",
   "metadata": {},
   "source": [
    "A function that removes all punctuation, all stop words, lemmatize the words and return a tokenized list of cleaned text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1b5e29e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Lemmatize the words\n",
    "    4. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    # Lemmatize the words\n",
    "    nopunc = [lemmatize.lemmatize(word) for word in nopunc.split()]\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ' '.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word.lower() for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20a5dcd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'name', 'Amal', 'working', 'work', 'using', 'rock', 'rock']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_process('Hello my name is Amal!! and i am working on this work using rocks and rock')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de709f2",
   "metadata": {},
   "source": [
    "Use apply for every text in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "528b7b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [people, would, take, step, back, make, case, ...\n",
       "1    [Law, enforcement, trained, shoot, apprehend, ...\n",
       "2    [Dont, reckon, black, life, matter, banner, he...\n",
       "3    [large, number, people, like, police, officer,...\n",
       "4    [Arab, dude, absolutely, right, shot, 6, extra...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newData['Text'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3ad77a",
   "metadata": {},
   "source": [
    "## 4. Vectorizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "671e44e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Data = []\n",
    "df = pd.DataFrame(new_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7825ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CommentId'] = newData['CommentId']\n",
    "df['VideoId'] = newData['VideoId']\n",
    "df['Text'] = newData['Text']\n",
    "df['IsToxic'] = newData['IsToxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7d38178d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsToxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugg2KwwX0V8-aXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>If only people would just take a step back and...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugg2s5AzSPioEXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>Law enforcement is not trained to shoot to app...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugg3dWTOxryFfHgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>Dont you reckon them 'black lives matter' bann...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugg7Gd006w1MPngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>There are a very large number of people who do...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugg8FfTbbNF8IngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>The Arab dude is absolutely right, he should h...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              CommentId      VideoId  \\\n",
       "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
       "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
       "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
       "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
       "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
       "\n",
       "                                                Text  IsToxic  \n",
       "0  If only people would just take a step back and...    False  \n",
       "1  Law enforcement is not trained to shoot to app...     True  \n",
       "2  Dont you reckon them 'black lives matter' bann...     True  \n",
       "3  There are a very large number of people who do...    False  \n",
       "4  The Arab dude is absolutely right, he should h...    False  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "46889268",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fadbac49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4386\n"
     ]
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(df['Text'])\n",
    "\n",
    "# Print total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "149fad65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a very large number of people who do not like police officers. They are called Criminals and its the reason we have police officers. The fact that Criminals do not like police officers is a testament to the good work that police officers do in protecting the public. When our children or our family are in danger, we do not hessitate to call for help, and we call the Police. Its about time people stopped complaining and started to give the Police some respect for the hard work and dedication that often requires them to put their lives on the line, to serve the public.\n"
     ]
    }
   ],
   "source": [
    "message4 = df['Text'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21ade944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 641)\t2\n",
      "  (0, 642)\t1\n",
      "  (0, 713)\t1\n",
      "  (0, 820)\t1\n",
      "  (0, 961)\t2\n",
      "  (0, 1001)\t1\n",
      "  (0, 1039)\t1\n",
      "  (0, 1430)\t1\n",
      "  (0, 1450)\t1\n",
      "  (0, 1674)\t1\n",
      "  (0, 1694)\t1\n",
      "  (0, 1781)\t1\n",
      "  (0, 1816)\t1\n",
      "  (0, 1829)\t1\n",
      "  (0, 2216)\t1\n",
      "  (0, 2277)\t1\n",
      "  (0, 2283)\t2\n",
      "  (0, 2290)\t1\n",
      "  (0, 2681)\t1\n",
      "  (0, 2707)\t4\n",
      "  (0, 2710)\t1\n",
      "  (0, 2830)\t2\n",
      "  (0, 2902)\t6\n",
      "  (0, 3027)\t1\n",
      "  (0, 3053)\t2\n",
      "  (0, 3081)\t1\n",
      "  (0, 3165)\t1\n",
      "  (0, 3246)\t1\n",
      "  (0, 3256)\t1\n",
      "  (0, 3443)\t1\n",
      "  (0, 3664)\t1\n",
      "  (0, 3711)\t1\n",
      "  (0, 3861)\t1\n",
      "  (0, 3936)\t1\n",
      "  (0, 4291)\t2\n",
      "(1, 4386)\n"
     ]
    }
   ],
   "source": [
    "bow4 = bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a14a0d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "police\n",
      "officer\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names()[2902])\n",
    "print(bow_transformer.get_feature_names()[2707])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "262e6ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_bow = bow_transformer.transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f0ddab7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (1000, 4386)\n",
      "Amount of Non-Zero occurences:  15856\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', text_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', text_bow.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f93d64",
   "metadata": {},
   "source": [
    "Now we'll use TF-IDF to give weight to each word in the comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19db95c",
   "metadata": {},
   "source": [
    "TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document). \n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ee854898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4291)\t0.2120470967470687\n",
      "  (0, 3936)\t0.08369391736037236\n",
      "  (0, 3861)\t0.1617147922778925\n",
      "  (0, 3711)\t0.12564438321929247\n",
      "  (0, 3664)\t0.11976432641897239\n",
      "  (0, 3443)\t0.13363811260110242\n",
      "  (0, 3256)\t0.11511075341292093\n",
      "  (0, 3246)\t0.15262758723850595\n",
      "  (0, 3165)\t0.10901622794005865\n",
      "  (0, 3081)\t0.10338381791641837\n",
      "  (0, 3053)\t0.23620686595889043\n",
      "  (0, 3027)\t0.1411790628409497\n",
      "  (0, 2902)\t0.41530956114947426\n",
      "  (0, 2830)\t0.12173186855109545\n",
      "  (0, 2710)\t0.14618011265623532\n",
      "  (0, 2707)\t0.32686048257534106\n",
      "  (0, 2681)\t0.12564438321929247\n",
      "  (0, 2290)\t0.13064543303457812\n",
      "  (0, 2283)\t0.14104111419376966\n",
      "  (0, 2277)\t0.08869496717565799\n",
      "  (0, 2216)\t0.14618011265623532\n",
      "  (0, 1829)\t0.1617147922778925\n",
      "  (0, 1816)\t0.12564438321929247\n",
      "  (0, 1781)\t0.11810343297944521\n",
      "  (0, 1694)\t0.0924389507876739\n",
      "  (0, 1674)\t0.11247102295580497\n",
      "  (0, 1450)\t0.11375204619529704\n",
      "  (0, 1430)\t0.09348154831840144\n",
      "  (0, 1039)\t0.1617147922778925\n",
      "  (0, 1001)\t0.15262758723850595\n",
      "  (0, 961)\t0.3052551744770119\n",
      "  (0, 820)\t0.1617147922778925\n",
      "  (0, 713)\t0.12155822799519155\n",
      "  (0, 642)\t0.12564438321929247\n",
      "  (0, 641)\t0.2084592935946304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(text_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b504abe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 4386)\n"
     ]
    }
   ],
   "source": [
    "text_tfidf = tfidf_transformer.transform(text_bow)\n",
    "print(text_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daef74b",
   "metadata": {},
   "source": [
    "## 5. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b82b98",
   "metadata": {},
   "source": [
    "Split the data! 70% for training and 30% for testing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a0a00d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 200 1000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_train, text_test, toxic_train, toxic_test = \\\n",
    "train_test_split(df['Text'], df['IsToxic'], test_size=0.2)\n",
    "\n",
    "print(len(text_train), len(text_test), len(text_train) + len(text_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60002c8",
   "metadata": {},
   "source": [
    "Create a pipeline\n",
    "\n",
    "Let's use the Naive Bayes classifier to start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e5906c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ec5fd727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x000002109D6AF790>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('classifier', MultinomialNB())])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(text_train,toxic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cb516f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipeline.predict(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "45b4ebea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.69      0.73       121\n",
      "        True       0.60      0.71      0.65        79\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.69      0.70      0.69       200\n",
      "weighted avg       0.71      0.69      0.70       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions,toxic_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5bb9c",
   "metadata": {},
   "source": [
    "not really good scores!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7131297",
   "metadata": {},
   "source": [
    "Let's try another classifier! SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1d958c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cb24d0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', svm.SVC()),  # train on TF-IDF vectors w/ SVM\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2d32bb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x000002109D6AF790>)),\n",
       "                ('tfidf', TfidfTransformer()), ('classifier', SVC())])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline2.fit(text_train,toxic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "56182e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = pipeline2.predict(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ab767b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.78      0.64      0.71       129\n",
      "        True       0.51      0.68      0.58        71\n",
      "\n",
      "    accuracy                           0.66       200\n",
      "   macro avg       0.65      0.66      0.64       200\n",
      "weighted avg       0.69      0.66      0.66       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions2,toxic_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d38b6",
   "metadata": {},
   "source": [
    "A bit better but could be better haha, Let's try another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4e5c5066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.75      0.74       160\n",
      "        True       0.70      0.67      0.69       140\n",
      "\n",
      "    accuracy                           0.71       300\n",
      "   macro avg       0.71      0.71      0.71       300\n",
      "weighted avg       0.71      0.71      0.71       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "pipeline3 = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', SGDClassifier(loss=\"hinge\", max_iter=100)),  # train on TF-IDF vectors w/ SGD\n",
    "])\n",
    "pipeline3.fit(text_train,toxic_train)\n",
    "predictions3 = pipeline3.predict(text_test)\n",
    "print(classification_report(predictions3,toxic_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "32da1d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.63      0.68       123\n",
      "        True       0.52      0.64      0.57        77\n",
      "\n",
      "    accuracy                           0.64       200\n",
      "   macro avg       0.63      0.64      0.63       200\n",
      "weighted avg       0.65      0.64      0.64       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "pipeline4 = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', tree.DecisionTreeClassifier()),  # train on TF-IDF vectors w/ SGD\n",
    "])\n",
    "pipeline4.fit(text_train,toxic_train)\n",
    "predictions4 = pipeline4.predict(text_test)\n",
    "print(classification_report(predictions4,toxic_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "be0a5402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.61      0.70       145\n",
      "        True       0.39      0.67      0.50        55\n",
      "\n",
      "    accuracy                           0.62       200\n",
      "   macro avg       0.61      0.64      0.60       200\n",
      "weighted avg       0.71      0.62      0.64       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "pipeline5 = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', BernoulliNB()),  # train on TF-IDF vectors w/ SGD\n",
    "])\n",
    "pipeline5.fit(text_train,toxic_train)\n",
    "predictions5 = pipeline5.predict(text_test)\n",
    "print(classification_report(predictions5,toxic_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6eba533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
